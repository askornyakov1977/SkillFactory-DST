{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from scipy.stats import t\n",
    "from importlib import reload\n",
    "import logging\n",
    "reload(logging)\n",
    "import funcs \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задаем формат логирования\n",
    "logging.basicConfig(\n",
    "   format=\"%(levelname)s: %(asctime)s: %(message)s\",\n",
    "    level=logging.INFO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cоздаем лог-файл\n",
    "logger = funcs.get_logger(path=\"logs/\", file=\"forecast.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: 2024-09-11 06:29:51,157: Data file: api01.csv\n",
      "INFO: 2024-09-11 06:29:51,161: Data shape: (40109, 4)\n",
      "INFO: 2024-09-11 06:29:51,179: Data head: \n",
      "         date      time          id  value\n",
      "0  12.08.2024  14:32:24  1723462344    912\n",
      "1  12.08.2024  14:30:40  1723462240    657\n",
      "2  12.08.2024  14:29:17  1723462157    872\n",
      "3  12.08.2024  14:28:14  1723462094    500\n",
      "4  12.08.2024  14:27:04  1723462024    852\n"
     ]
    }
   ],
   "source": [
    "# Считаем файл-csv импортированный из БД мониторинга в датафрейм\n",
    "file_name = 'api01.csv'\n",
    "data = pd.read_csv(file_name, sep=' ')\n",
    "logger.info(f\"Data file: {file_name}\")\n",
    "logger.info(f\"Data shape: {data.shape}\")\n",
    "logger.info(f\"Data head: \\n{data.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: 2024-09-11 07:14:51,538: Number of entries before filling in gaps: 1440\n",
      "INFO: 2024-09-11 07:14:51,588: Number of entries after filling in the blanks: 1440\n",
      "INFO: 2024-09-11 07:14:51,642: Basic statistical characteristics of end-to-end values of a time series: \n",
      "        lower_bound       median  upper_bound\n",
      "count  1440.000000  1440.000000  1440.000000\n",
      "mean    300.369132   343.182986   478.380243\n",
      "std      11.924069    31.102221   139.257811\n",
      "min     255.800000   287.000000   314.850000\n",
      "25%     293.000000   322.000000   368.000000\n",
      "50%     301.000000   336.500000   429.875000\n",
      "75%     307.900000   357.500000   559.625000\n",
      "max     351.050000   511.000000  1541.250000\n",
      "INFO: 2024-09-11 07:14:58,507: Transformed data: \n",
      "                       y\n",
      "date_time               \n",
      "2024-07-13 14:33:00  785\n",
      "2024-07-13 14:34:00  547\n",
      "2024-07-13 14:35:00  448\n",
      "2024-07-13 14:36:00  415\n",
      "2024-07-13 14:38:00  381\n",
      "INFO: 2024-09-11 07:14:58,516: Number of records before filling gaps and merging duplicates: 40109\n",
      "INFO: 2024-09-11 07:14:58,534: Number of records after filling gaps and merging duplicates: 43200\n",
      "INFO: 2024-09-11 07:15:35,023: Data with a new target feature: \n",
      "                   y       y_clean\n",
      "count  35971.000000  43200.000000\n",
      "mean     421.176364    350.381806\n",
      "std      527.940351     56.343374\n",
      "min        0.000000    262.000000\n",
      "25%      308.000000    319.000000\n",
      "50%      334.000000    335.000000\n",
      "75%      394.000000    361.000000\n",
      "max    25352.000000   1034.000000\n"
     ]
    }
   ],
   "source": [
    "# Получим выборку с очищенными данными\n",
    "data_cleaned = funcs.get_data_cleaned(data, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Производим десериализацию и извлекаем модель из файла формата pkl\n",
    "with open('pipeline.pkl', 'rb') as pkl_file:\n",
    "    pipe = pickle.load(pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_test = pd.DatetimeIndex(pd.date_range(data_cleaned.index.max() + pd.Timedelta(1, 'min'), periods=1440, freq='min'),\n",
    "                name='date_time')\n",
    "X = pd.DataFrame(index=index_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: 2024-09-11 06:30:43,259: Shape before transform: (1440, 0)\n",
      "INFO: 2024-09-11 06:30:43,263: Shape after transform: (1440, 85)\n"
     ]
    }
   ],
   "source": [
    "# Трансформируем исходные данные \n",
    "X_transformed = funcs.get_data_transformed(X)\n",
    "logger.info('Shape before transform: {}'.format(X.shape))\n",
    "logger.info('Shape after transform: {}'.format(X_transformed.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделаем предсказание обучающей выборки\n",
    "y_pred = pipe.predict(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объявим вспомогательную функцию по вычислению остаточной стандартной ошибки: residual standard error\n",
    "def get_rse(y_true, y_predicted):\n",
    "    \"\"\"\n",
    "    - y_true: Actual values\n",
    "    - y_predicted: Predicted values\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    n = y_true.shape[0]\n",
    "    if n - 2 > 0:\n",
    "        y_predicted = np.array(y_predicted)\n",
    "        rss = np.sum(np.square(y_true - y_predicted))\n",
    "        return np.sqrt(rss / (n - 2))\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зададим параметры вычисления \n",
    "prediction_level = 0.95\n",
    "boundaries = round((1 - prediction_level) / 2, 2)\n",
    "quantiles = [boundaries, prediction_level + boundaries]\n",
    "# Зададим степень уверенности\n",
    "gamma = prediction_level\n",
    "# Уровень значимости\n",
    "alpha = 1 - gamma\n",
    "# Зададим продолжительность сезона в минутах\n",
    "season = 1440\n",
    "# Размер выборки\n",
    "n = int(data_cleaned.shape[0] / season)\n",
    "# Число степеней свободы\n",
    "k = n - 1\n",
    "# t-критическое\n",
    "t_crit = -t.ppf(alpha/2, k)\n",
    "# Объявим функцию для вычисления границы интервала прогнозирования для каждой минуты тестовой выборки\n",
    "def get_prediction_interval(series):\n",
    "  # Получим серию значений временного ряда за аналогичные минуты в пред. n суток\n",
    "  y = data_cleaned.y[data_cleaned.index.time == datetime.time(series.name.hour, series.name.minute)]\n",
    "  # Расчитаем отдельно верхную и нижнюю границы\n",
    "  # Отфильтруем актуальные значения отдельно\n",
    "  y_true_upper = y[y>series.y]\n",
    "  y_true_lower = y[y<series.y]\n",
    "  # Получим остаточную стандартную ошибку\n",
    "  rse_upper = get_rse(y_true_upper, series.y)\n",
    "  rse_lower = get_rse(y_true_lower, series.y)\n",
    "  # погрешность\n",
    "  eps_upper = t_crit * rse_upper\n",
    "  eps_lower = t_crit * rse_lower\n",
    "  # левая (нижняя) граница\n",
    "  lower_bound = series.y - eps_lower\n",
    "  # правая (верхняя) граница\n",
    "  upper_bound = series.y + eps_upper\n",
    "  return lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычислим границы интервала прогнозирования для каждой минуты прогнозной выборки\n",
    "# Cохраним результат в выборку для хранения прогноза\n",
    "df_y_pred = pd.DataFrame({'y': y_pred}, index=X_transformed.index)\n",
    "df_y_pred[['lower_bound', 'upper_bound']] = df_y_pred.apply(get_prediction_interval, axis=1).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: 2024-09-11 07:21:01,224: Main statistical characteristics of the model predictions: \n",
      "                 y  lower_bound  upper_bound\n",
      "count  1440.000000  1440.000000  1440.000000\n",
      "mean    335.484527   286.542925   439.187703\n",
      "std      26.230752    20.610254   114.576162\n",
      "min     285.725159   172.170042   304.012910\n",
      "25%     317.118269   276.372262   356.633470\n",
      "50%     328.786351   288.266261   395.861327\n",
      "75%     349.429326   299.067340   497.667361\n",
      "max     459.134506   344.729679  1298.835279\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Main statistical characteristics of the model predictions: \\n{df_y_pred.describe()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: 2024-09-11 07:22:05,116: Model predictions are saved to file: prediction.csv\n"
     ]
    }
   ],
   "source": [
    "# Сохраним предсказания на сутки вперед в csv файл.\n",
    "file_name = 'prediction.csv' \n",
    "df_y_pred.to_csv(file_name)\n",
    "logger.info(f'Model predictions are saved to file: {file_name}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
